{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTJl3Lp8JgnM",
        "colab_type": "text"
      },
      "source": [
        "# Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl6aykEJLF8b",
        "colab_type": "text"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vesln-yKxc2",
        "colab_type": "code",
        "outputId": "a4fa6bb9-b117-4593-fa19-0e9c5e373788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "from itertools import combinations\n",
        "from math import sqrt\n",
        "import random\n",
        "from keras.layers import Concatenate, Dense, Dot, Dropout, Embedding, Input, Reshape\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB7FAGXPLIjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STUDENT_ID = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cheEmZjxLOhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(2019)\n",
        "np.random.seed(2019)\n",
        "tensorflow.set_random_seed(2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YUAJhpgOPjK",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7r0Fly4LRk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse(pred, actual):\n",
        "    # Ignore nonzero terms.\n",
        "    pred = pred[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(pred, actual))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgcNYkFdLVHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_deepwide_model(len_continuous, deep_vocab_lens, len_wide, embed_size):\n",
        "    input_list = []\n",
        "    continuous_input = Input(shape=(len_continuous,), dtype='float32', name='continuous_input')\n",
        "    input_list.append(continuous_input)\n",
        "\n",
        "    emb_list = []\n",
        "    for vocab_size in deep_vocab_lens:\n",
        "        _input = Input(shape=(1,), dtype='int32')\n",
        "        input_list.append(_input)\n",
        "        _emb = Embedding(output_dim=embed_size, input_dim=vocab_size, input_length=1)(_input)\n",
        "        _emb = Reshape((embed_size,))(_emb)\n",
        "        emb_list.append(_emb)\n",
        "\n",
        "    deep_input = Concatenate()(emb_list + [continuous_input])\n",
        "    dense_1 = Dense(256, activation='relu')(deep_input)\n",
        "    dense_1_dp = Dropout(0.0)(dense_1)\n",
        "    dense_2 = Dense(128, activation='relu')(dense_1_dp)\n",
        "    dense_2_dp = Dropout(0.0)(dense_2)\n",
        "    dense_3 = Dense(64, activation='relu')(dense_2_dp)\n",
        "    dense_3_dp = Dropout(0.0)(dense_3)\n",
        "\n",
        "    wide_input = Input(shape=(len_wide,), dtype='float32')\n",
        "    input_list.append(wide_input)\n",
        "    \n",
        "    fc_input = Concatenate()([dense_3_dp, wide_input])\n",
        "    model_output = Dense(1)(fc_input)\n",
        "    model = Model(inputs=input_list,\n",
        "                  outputs=model_output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZbeWtizLYXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_continuous_features(df, continuous_columns):\n",
        "    continuous_features = df[continuous_columns].values\n",
        "    return continuous_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO3ZPZvILa2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_k_p_combinations(df, comb_p, topk, output_freq=False):\n",
        "    def get_category_combinations(categories_str, comb_p=2):\n",
        "        categories = categories_str.split(', ')\n",
        "        return list(combinations(categories, comb_p))\n",
        "    all_categories_p_combos = df[\"item_categories\"].apply(\n",
        "        lambda x: get_category_combinations(x, comb_p)).values.tolist()\n",
        "    all_categories_p_combos = [tuple(t) for item in all_categories_p_combos for t in item]\n",
        "    tmp = dict(Counter(all_categories_p_combos))\n",
        "    sorted_categories_combinations = list(sorted(tmp.items(), key=lambda x: x[1], reverse=True))\n",
        "    if output_freq:\n",
        "        return sorted_categories_combinations[:topk]\n",
        "    else:\n",
        "        return [t[0] for t in sorted_categories_combinations[:topk]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf2n5b7_LeR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wide_features(df):\n",
        "    def categories_to_binary_output(categories):\n",
        "        binary_output = [0 for _ in range(len(selected_categories_to_idx))]\n",
        "        for category in categories.split(', '):\n",
        "            if category in selected_categories_to_idx:\n",
        "                binary_output[selected_categories_to_idx[category]] = 1\n",
        "            else:\n",
        "                binary_output[0] = 1\n",
        "        return binary_output\n",
        "    def categories_cross_transformation(categories):\n",
        "        current_category_set = set(categories.split(', '))\n",
        "        corss_transform_output = [0 for _ in range(len(top_combinations))]\n",
        "        for k, comb_k in enumerate(top_combinations):\n",
        "            if len(current_category_set & comb_k) == len(comb_k):\n",
        "                corss_transform_output[k] = 1\n",
        "            else:\n",
        "                corss_transform_output[k] = 0\n",
        "        return corss_transform_output\n",
        "\n",
        "    category_binary_features = np.array(df.item_categories.apply(\n",
        "        lambda x: categories_to_binary_output(x)).values.tolist())\n",
        "    category_corss_transform_features = np.array(df.item_categories.apply(\n",
        "        lambda x: categories_cross_transformation(x)).values.tolist())\n",
        "    return np.concatenate((category_binary_features, category_corss_transform_features), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYJ5_7BzS4d3",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81rKp8GJWcPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_YwEnvS6w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0cnvlH6Lo1u",
        "colab_type": "text"
      },
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPQY0dFiLlui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_df = pd.read_csv(\"data/train.csv\")\n",
        "val_df = pd.read_csv(\"data/valid.csv\")\n",
        "te_df = pd.read_csv(\"data/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViZ4V48MLvf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_ratings = tr_df.stars.values\n",
        "val_ratings = val_df.stars.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfD_2WKOL0K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_df = pd.read_json(\"data/user.json\")\n",
        "item_df = pd.read_json(\"data/business.json\")\n",
        "user_df = user_df.rename(index=str, columns={t: 'user_' + t for t in user_df.columns if t != 'user_id'})\n",
        "item_df = item_df.rename(index=str, columns={t: 'item_' + t for t in item_df.columns if t != 'business_id'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQyKOgTvL56A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_df[\"index\"] = tr_df.index\n",
        "val_df[\"index\"]  = val_df.index\n",
        "te_df[\"index\"] = te_df.index\n",
        "tr_df = pd.merge(pd.merge(tr_df, user_df, on='user_id'), item_df, on='business_id').sort_values(by=['index']).reset_index(drop=True)\n",
        "val_df = pd.merge(pd.merge(val_df, user_df, on='user_id'), item_df, on='business_id').sort_values(by=['index']).reset_index(drop=True)\n",
        "te_df = pd.merge(pd.merge(te_df, user_df, on='user_id'), item_df, on='business_id').sort_values(by=['index']).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsubGlYYz8qN",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zgMRqIEcSgj",
        "colab_type": "code",
        "outputId": "588dd796-0c9f-4b04-c861-34f75157b80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "attributes = tr_df[\"item_attributes\"].apply(lambda attributes: attributes.keys() if attributes is not None else ()).values\n",
        "all_attributes = []\n",
        "for review_attributes in attributes:\n",
        "    for attribute in review_attributes:\n",
        "        all_attributes.append(attribute)\n",
        "all_attributes, all_attributes_count = np.unique(all_attributes, return_counts=True)\n",
        "all_attributes = all_attributes[np.flipud(np.argsort(all_attributes_count))]\n",
        "all_attributes_count = np.flipud(np.sort(all_attributes_count))\n",
        "print(all_attributes, all_attributes_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['RestaurantsPriceRange2' 'BusinessParking' 'BikeParking' 'WiFi'\n",
            " 'GoodForKids' 'BusinessAcceptsCreditCards' 'RestaurantsTakeOut'\n",
            " 'OutdoorSeating' 'Alcohol' 'Caters' 'RestaurantsGoodForGroups' 'HasTV'\n",
            " 'RestaurantsDelivery' 'Ambience' 'NoiseLevel' 'RestaurantsReservations'\n",
            " 'RestaurantsAttire' 'GoodForMeal' 'RestaurantsTableService'\n",
            " 'WheelchairAccessible' 'Music' 'BusinessAcceptsBitcoin' 'BestNights'\n",
            " 'GoodForDancing' 'HappyHour' 'DogsAllowed' 'BYOBCorkage' 'CoatCheck'\n",
            " 'Smoking' 'ByAppointmentOnly' 'Corkage' 'DriveThru' 'BYOB' 'AgesAllowed'\n",
            " 'AcceptsInsurance' 'DietaryRestrictions' 'Open24Hours'\n",
            " 'RestaurantsCounterService' 'HairSpecializesIn'] [94646 94417 91910 87877 87635 87404 86762 86171 85789 85162 84574 83762\n",
            " 83756 83621 83233 83230 81647 75913 40984 25519 18664 17012 16751 16389\n",
            " 14233 13518 11845 10414 10226  8890  6559  6398   544   478   335   205\n",
            "   177   167    56]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaSK7iIJfio6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_attribute_value(attributes, attribute_key, value_map, not_exist_value):\n",
        "    if attribute_key in attributes:\n",
        "        for value, parsed_value in value_map:\n",
        "            if attributes[attribute_key] == value:\n",
        "                return parsed_value\n",
        "    return not_exist_value\n",
        "\n",
        "tr_df[\"item_attributes_parsed\"] = tr_df[\"item_attributes\"].apply(lambda attributes: attributes if attributes is not None else {})\n",
        "val_df[\"item_attributes_parsed\"] = val_df[\"item_attributes\"].apply(lambda attributes: attributes if attributes is not None else {})\n",
        "te_df[\"item_attributes_parsed\"] = te_df[\"item_attributes\"].apply(lambda attributes: attributes if attributes is not None else {})\n",
        "\n",
        "tr_df[\"item_RestaurantsPriceRange2\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: int(attributes[\"RestaurantsPriceRange2\"]) if attributes is not None and \"RestaurantsPriceRange2\" in attributes else 0)\n",
        "tr_df[\"item_BikeParking\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BikeParking\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_GoodForKids\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"GoodForKids\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_BusinessAcceptsCreditCards\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BusinessAcceptsCreditCards\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_RestaurantsTakeOut\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTakeOut\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_OutdoorSeating\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"OutdoorSeating\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_Alcohol\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Alcohol\", [(\"full_bar\", 0), (\"u'full_bar'\", 0), (\"beer_and_wine\", 1), (\"u'beer_and_wine'\", 1)], -1))\n",
        "tr_df[\"item_Caters\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Caters\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_RestaurantsGoodForGroups\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsGoodForGroups\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_HasTV\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"HasTV\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_RestaurantsDelivery\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsDelivery\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_NoiseLevel\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"NoiseLevel\", [(\"u'quiet'\", 0), (\"quiet\", 0), (\"u'average'\", 1), (\"average\", 1), (\"u'loud'\", 2), (\"loud\", 2), (\"u'very_loud'\", 3), (\"very_loud\", 3)], -1))\n",
        "tr_df[\"item_RestaurantsReservations\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsReservations\", [('True', 1), ('False', 0)], -1))\n",
        "tr_df[\"item_RestaurantsAttire\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsAttire\", [(\"u'casual'\", 0), (\"casual\", 0), (\"u'dressy'\", 1), (\"dressy\", 1)], -1))\n",
        "tr_df[\"item_RestaurantsTableService\"] = tr_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTableService\", [('True', 1), ('False', 0)], -1))\n",
        "\n",
        "val_df[\"item_RestaurantsPriceRange2\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: int(attributes[\"RestaurantsPriceRange2\"]) if attributes is not None and \"RestaurantsPriceRange2\" in attributes else 0)\n",
        "val_df[\"item_BikeParking\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BikeParking\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_GoodForKids\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"GoodForKids\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_BusinessAcceptsCreditCards\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BusinessAcceptsCreditCards\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_RestaurantsTakeOut\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTakeOut\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_OutdoorSeating\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"OutdoorSeating\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_Alcohol\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Alcohol\", [(\"full_bar\", 0), (\"u'full_bar'\", 0), (\"beer_and_wine\", 1), (\"u'beer_and_wine'\", 1)], -1))\n",
        "val_df[\"item_Caters\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Caters\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_RestaurantsGoodForGroups\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsGoodForGroups\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_HasTV\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"HasTV\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_RestaurantsDelivery\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsDelivery\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_NoiseLevel\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"NoiseLevel\", [(\"u'quiet'\", 0), (\"quiet\", 0), (\"u'average'\", 1), (\"average\", 1), (\"u'loud'\", 2), (\"loud\", 2), (\"u'very_loud'\", 3), (\"very_loud\", 3)], -1))\n",
        "val_df[\"item_RestaurantsReservations\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsReservations\", [('True', 1), ('False', 0)], -1))\n",
        "val_df[\"item_RestaurantsAttire\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsAttire\", [(\"u'casual'\", 0), (\"casual\", 0), (\"u'dressy'\", 1), (\"dressy\", 1)], -1))\n",
        "val_df[\"item_RestaurantsTableService\"] = val_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTableService\", [('True', 1), ('False', 0)], -1))\n",
        "\n",
        "te_df[\"item_RestaurantsPriceRange2\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: int(attributes[\"RestaurantsPriceRange2\"]) if attributes is not None and \"RestaurantsPriceRange2\" in attributes else 0)\n",
        "te_df[\"item_BikeParking\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BikeParking\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_GoodForKids\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"GoodForKids\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_BusinessAcceptsCreditCards\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"BusinessAcceptsCreditCards\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_RestaurantsTakeOut\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTakeOut\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_OutdoorSeating\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"OutdoorSeating\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_Alcohol\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Alcohol\", [(\"full_bar\", 0), (\"u'full_bar'\", 0), (\"beer_and_wine\", 1), (\"u'beer_and_wine'\", 1)], -1))\n",
        "te_df[\"item_Caters\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"Caters\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_RestaurantsGoodForGroups\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsGoodForGroups\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_HasTV\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"HasTV\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_RestaurantsDelivery\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsDelivery\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_NoiseLevel\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"NoiseLevel\", [(\"u'quiet'\", 0), (\"quiet\", 0), (\"u'average'\", 1), (\"average\", 1), (\"u'loud'\", 2), (\"loud\", 2), (\"u'very_loud'\", 3), (\"very_loud\", 3)], -1))\n",
        "te_df[\"item_RestaurantsReservations\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsReservations\", [('True', 1), ('False', 0)], -1))\n",
        "te_df[\"item_RestaurantsAttire\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsAttire\", [(\"u'casual'\", 0), (\"casual\", 0), (\"u'dressy'\", 1), (\"dressy\", 1)], -1))\n",
        "te_df[\"item_RestaurantsTableService\"] = te_df[\"item_attributes_parsed\"].apply(lambda attributes: get_attribute_value(attributes, \"RestaurantsTableService\", [('True', 1), ('False', 0)], -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Lk8l3ZXwf1",
        "colab_type": "text"
      },
      "source": [
        "## Continuous Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnDpLJVoL_IF",
        "colab_type": "code",
        "outputId": "85cb0c26-cac7-4a7c-acb3-ae1b9b1bb254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Prepare continuous features...\")\n",
        "continuous_columns = [\n",
        "    \"user_average_stars\",\n",
        "#     \"user_cool\",\n",
        "#     \"user_fans\",\n",
        "    \"user_review_count\",\n",
        "    \"user_useful\",\n",
        "#     \"user_funny\",\n",
        "#     \"item_is_open\",\n",
        "#     \"item_latitude\",\n",
        "#     \"item_longitude\",\n",
        "    \"item_review_count\",\n",
        "    \"item_stars\",\n",
        "    \"item_RestaurantsPriceRange2\",\n",
        "#     \"item_BikeParking\",\n",
        "    \"item_GoodForKids\",\n",
        "#     \"item_BusinessAcceptsCreditCards\",\n",
        "#     \"item_RestaurantsTakeOut\",\n",
        "#     \"item_OutdoorSeating\",\n",
        "#     \"item_Alcohol\",\n",
        "#     \"item_Caters\",\n",
        "#     \"item_RestaurantsGoodForGroups\",\n",
        "#     \"item_HasTV\",\n",
        "#     \"item_NoiseLevel\",\n",
        "#     \"item_RestaurantsDelivery\",\n",
        "#     \"item_RestaurantsReservations\",\n",
        "#     \"item_RestaurantsAttire\",\n",
        "#     \"item_RestaurantsTableService\"\n",
        "]\n",
        "tr_continuous_features = get_continuous_features(tr_df, continuous_columns)\n",
        "val_continuous_features = get_continuous_features(val_df, continuous_columns)\n",
        "te_continuous_features = get_continuous_features(te_df, continuous_columns)\n",
        "scaler = StandardScaler().fit(tr_continuous_features)\n",
        "tr_continuous_features = scaler.transform(tr_continuous_features)\n",
        "val_continuous_features = scaler.transform(val_continuous_features)\n",
        "te_continuous_features = scaler.transform(te_continuous_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepare continuous features...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52kk5c8nXyu7",
        "colab_type": "text"
      },
      "source": [
        "## Deep Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3fHUf1MEzs",
        "colab_type": "code",
        "outputId": "086de792-e7ac-4412-fc16-8032f39336ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Prepare deep features...\")\n",
        "item_deep_columns = [\n",
        "    \"item_city\",\n",
        "#     \"item_postal_code\",\n",
        "    \"item_state\"\n",
        "]\n",
        "item_deep_vocab_lens = []\n",
        "for col_name in item_deep_columns:\n",
        "    tmp = item_df[col_name].unique()\n",
        "    vocab = dict(zip(tmp, range(1, len(tmp) + 1)))\n",
        "    item_deep_vocab_lens.append(len(vocab) + 1)\n",
        "    item_df[col_name + \"_idx\"] = item_df[col_name].apply(lambda x: vocab[x] if x in vocab else 0)\n",
        "item_deep_idx_columns = [t + \"_idx\" for t in item_deep_columns]\n",
        "item_to_deep_features = dict(zip(item_df.business_id.values, item_df[item_deep_idx_columns].values.tolist()))\n",
        "tr_deep_features = np.array(tr_df.business_id.apply(lambda x: item_to_deep_features[x]).values.tolist())\n",
        "val_deep_features = np.array(val_df.business_id.apply(lambda x: item_to_deep_features[x]).values.tolist())\n",
        "te_deep_features = np.array(te_df.business_id.apply(lambda x: item_to_deep_features[x]).values.tolist())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepare deep features...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmZq20RpX0tA",
        "colab_type": "text"
      },
      "source": [
        "## Wide Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOFcNhO3X9Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   Prepare binary encoding for each selected categories\n",
        "all_categories = [category for category_list in item_df.item_categories.values for category in category_list.split(\", \")]\n",
        "category_sorted = sorted(Counter(all_categories).items(), key=lambda x: x[1], reverse=True)\n",
        "selected_categories = [t[0] for t in category_sorted[:500]]\n",
        "selected_categories_to_idx = dict(zip(selected_categories, range(1, len(selected_categories) + 1)))\n",
        "selected_categories_to_idx['unk'] = 0\n",
        "idx_to_selected_categories = {val: key for key, val in selected_categories_to_idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfrMxEUkX-Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#   Prepare Cross transformation for each categories\n",
        "top_combinations = []\n",
        "top_combinations += get_top_k_p_combinations(tr_df, 2, 20, output_freq=False)\n",
        "top_combinations += get_top_k_p_combinations(tr_df, 3, 15, output_freq=False)\n",
        "top_combinations += get_top_k_p_combinations(tr_df, 4, 15, output_freq=False)\n",
        "top_combinations = [set(t) for t in top_combinations]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAHU8rcyX-zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_wide_features = get_wide_features(tr_df)\n",
        "val_wide_features = get_wide_features(val_df)\n",
        "te_wide_features = get_wide_features(te_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z_pX0eEX28A",
        "colab_type": "text"
      },
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1lNBjjMYcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build input\n",
        "tr_features = []\n",
        "tr_features.append(tr_continuous_features.tolist())\n",
        "tr_features += [tr_deep_features[:,i].tolist() for i in range(len(tr_deep_features[0]))]\n",
        "tr_features.append(tr_wide_features.tolist())\n",
        "val_features = []\n",
        "val_features.append(val_continuous_features.tolist())\n",
        "val_features += [val_deep_features[:,i].tolist() for i in range(len(val_deep_features[0]))]\n",
        "val_features.append(val_wide_features.tolist())\n",
        "te_features = []\n",
        "te_features.append(te_continuous_features.tolist())\n",
        "te_features += [te_deep_features[:,i].tolist() for i in range(len(te_deep_features[0]))]\n",
        "te_features.append(te_wide_features.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2UZLg7GXrig",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFLtKlNDMc6Q",
        "colab_type": "code",
        "outputId": "fc083699-9512-4038-ccf3-6eb6dd329056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# Model training\n",
        "deepwide_model = build_deepwide_model(\n",
        "    len(tr_continuous_features[0]),\n",
        "    item_deep_vocab_lens,  \n",
        "    len(tr_wide_features[0]), \n",
        "    embed_size=EMBEDDING_SIZE)\n",
        "deepwide_model.compile(\n",
        "    optimizer='adagrad',\n",
        "    loss='mse'\n",
        ")\n",
        "history = deepwide_model.fit(\n",
        "    tr_features,\n",
        "    tr_ratings,\n",
        "    validation_data=(val_features, val_ratings),\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        ModelCheckpoint('model.h5'),\n",
        "        EarlyStopping(restore_best_weights=True)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "100000/100000 [==============================] - 12s 123us/step - loss: 1.1067 - val_loss: 1.0657\n",
            "Epoch 2/10\n",
            "100000/100000 [==============================] - 10s 98us/step - loss: 1.0610 - val_loss: 1.0641\n",
            "Epoch 3/10\n",
            "100000/100000 [==============================] - 10s 98us/step - loss: 1.0551 - val_loss: 1.0613\n",
            "Epoch 4/10\n",
            "100000/100000 [==============================] - 10s 98us/step - loss: 1.0520 - val_loss: 1.0605\n",
            "Epoch 5/10\n",
            "100000/100000 [==============================] - 10s 101us/step - loss: 1.0500 - val_loss: 1.0597\n",
            "Epoch 6/10\n",
            "100000/100000 [==============================] - 11s 106us/step - loss: 1.0479 - val_loss: 1.0578\n",
            "Epoch 7/10\n",
            "100000/100000 [==============================] - 10s 104us/step - loss: 1.0466 - val_loss: 1.0567\n",
            "Epoch 8/10\n",
            "100000/100000 [==============================] - 10s 98us/step - loss: 1.0449 - val_loss: 1.0592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8X2SegqXtpA",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpiWhD35M6Pz",
        "colab_type": "code",
        "outputId": "46d87e75-de43-40df-881a-fbd6f06ae799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Make Prediction\n",
        "y_pred = deepwide_model.predict(tr_features)\n",
        "print(\"TRAIN RMSE: \", rmse(y_pred, tr_ratings))\n",
        "y_pred = deepwide_model.predict(val_features)\n",
        "print(\"VALID RMSE: \", rmse(y_pred, val_ratings))\n",
        "y_pred = deepwide_model.predict(te_features)\n",
        "res_df = pd.DataFrame()\n",
        "res_df['pred'] = y_pred[:, 0]\n",
        "res_df.to_csv(\"{}.csv\".format(STUDENT_ID), index=False)\n",
        "print(\"Writing test predictions to file done.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN RMSE:  1.0205543193657187\n",
            "VALID RMSE:  1.0279644654628406\n",
            "Writing test predictions to file done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKc1rRzeM_e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}